{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa2c5e6",
   "metadata": {},
   "source": [
    "## <span style=color:blue>DISCUSSION 5 - BENCHMARKING and VISUALIZATION</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee4f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text as sql_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad14751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an utilities file util.py in a folder benchmarking and import it\n",
    "sys.path.append('benchmarking/')\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2060cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# test that utils.py has been imported well\n",
    "util.hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d047ad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the env file \n",
    "\n",
    "dotenv_path = 'variables.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbb12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the env variables\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "schema = os.getenv('DISC_4_SCHEMA')\n",
    "port = os.getenv('DISC_4_PORT')\n",
    "host = os.getenv('DISC_4_HOST')\n",
    "database = os.getenv('DISC_4_DB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832a1e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created db engine.\n"
     ]
    }
   ],
   "source": [
    "# Create the db engine \n",
    "\n",
    "db_eng = create_engine(f\"postgresql+psycopg2://postgres:postgres@{host}:{port}/{database}\",\n",
    "                       connect_args={'options': '-csearch_path={}'.format(schema)},\n",
    "                       isolation_level = 'SERIALIZABLE')\n",
    "\n",
    "print(\"Successfully created db engine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498969b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2009', 56),\n",
      " ('2010', 449),\n",
      " ('2011', 1905),\n",
      " ('2012', 3872),\n",
      " ('2013', 7317),\n",
      " ('2014', 14203),\n",
      " ('2015', 28465),\n",
      " ('2016', 42825),\n",
      " ('2017', 39464),\n",
      " ('2018', 41836),\n",
      " ('2019', 41273),\n",
      " ('2020', 10239),\n",
      " ('2021', 18463),\n",
      " ('2022', 26739),\n",
      " ('2023', 22383),\n",
      " ('2024', 511)]\n"
     ]
    }
   ],
   "source": [
    "# Check to see the count of tables \n",
    "\n",
    "q = \"\"\"select left(to_char(date, 'YYYY-MM-DD'),4) as year, count(*)\n",
    "from reviews\n",
    "group by year\n",
    "order by year\"\"\"\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    result = conn.execute(sql_text(q))\n",
    "\n",
    "result_list = result.fetchall()\n",
    "\n",
    "pprint.pp(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function build_query_listings_reviews to build a query for reviews for each year\n",
    "\n",
    "date_start = '2015-01-01'\n",
    "date_end = '2015-12-31'\n",
    "\n",
    "# BUILD THE QUERY HERE ------- P1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce80972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to build queries from the year 2009 to 2024 ------- P2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2182606e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m time_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,count):\n\u001b[1;32m----> 7\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Open new db connection for each execution of the query to avoid multithreading\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m db_eng\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a function to calculate the performance of a single query from q_dict\n",
    "\n",
    "count = 10\n",
    "\n",
    "time_list = []\n",
    "for i in range(0,count):\n",
    "    time_start = datetime.now()\n",
    "    # Open new db connection for each execution of the query to avoid multithreading\n",
    "    with db_eng.connect() as conn:\n",
    "        df = pd.read_sql(q_dict['listings_join_review_2015'], con=conn)\n",
    "\n",
    "    time_end = datetime.now()\n",
    "    diff = util.time_diff(time_start, time_end)\n",
    "    time_list.append(diff)\n",
    "\n",
    "pprint.pp(time_list)\n",
    "print('mean', round(sum(time_list)/len(time_list), 4), 'min', \\\n",
    "        round(min(time_list), 4), 'max', \\\n",
    "        round(max(time_list), 4), 'std', \\\n",
    "        round(np.std(time_list), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc330789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding and dropping indexes in the table reviews ---- P3\n",
    "\n",
    "# WRITE THE QUERIES BELOW\n",
    "\n",
    "\n",
    "# DB CONNECTION\n",
    "with db_eng.connect() as conn:\n",
    "    conn.execute(sql_text(q_create_date_in_reviews))\n",
    "    result_reviews_add = conn.execute(sql_text(q_show_indexes_for_reviews))\n",
    "    print('The set of indexes on reviews is: ')\n",
    "    print(result_reviews_add.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ef050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each year ---- P4\n",
    "\n",
    "#Initialize the count to 20\n",
    "count = 20\n",
    "\n",
    "perf_details = {}\n",
    "perf_details['with_bm'] = {}\n",
    "\n",
    "# Iterate through all the queries in q_dict --- BUILD THE QUERY BELOW\n",
    "\n",
    "\n",
    "print(perf_details)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c536bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate function for the above and put it in the util file. ------ P5\n",
    "# Run it again to be sure  \n",
    "\n",
    "count = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ce218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the index on date in reviews\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    conn.execute(sql_text(q_drop_date_in_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the same metrics for review without the index\n",
    "\n",
    "perf_details['without_bm'] = util.calc_time_diff_per_year(db_eng, count, q_dict)\n",
    "\n",
    "pp.pprint(perf_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a way to save this data somewhere....save it in a json file (pref_data.json)\n",
    "\n",
    "perf_file = 'perf_data.json'\n",
    "\n",
    "try:\n",
    "    old_perf_summary = util.fetch_perf_data(perf_file)\n",
    "    print('Successfully read file perf_data/' + perf_file)\n",
    "except:\n",
    "    print('Not successful in finding file perf_data/' + perf_file + '; so creating it')\n",
    "    old_perf_summary = {}\n",
    "    util.write_perf_data(perf_details, perf_file)\n",
    "    \n",
    "util.write_perf_data(perf_details, perf_file)\n",
    "\n",
    "# With this we have completed the benchmarking test using a single index on the date column of the reviews table\n",
    "# However let's include visualization to see our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data from a file ------ P6\n",
    "with open('perf_data/perf_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Printing the loaded file\n",
    "print(json.dumps(data, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the json into dataframes ----- P7\n",
    "\n",
    "df_with_bm = pd.DataFrame(data['with_bm']).transpose()\n",
    "df_without_bm = pd.DataFrame(data['without_bm']).transpose()\n",
    "\n",
    "print(df_with_bm)\n",
    "print(df_without_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare the performances with and without indexes with respect to average time ----- P8\n",
    "# Also include the average time comparison lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d02014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare the performances with and without indexes with respect to standard deviation\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot standard deviations\n",
    "plt.plot(df_with_bm.index, df_with_bm['std'], label='With BM', marker='o')\n",
    "plt.plot(df_without_bm.index, df_without_bm['std'], label='Without BM', marker='x')\n",
    "\n",
    "# Calculate and plot the average standard deviation for with_bm and without_bm\n",
    "avg_std_with_bm = df_with_bm['std'].mean()\n",
    "avg_std_without_bm = df_without_bm['std'].mean()\n",
    "\n",
    "plt.axhline(y=avg_std_with_bm, color='blue', linestyle='--', label=f'Avg. Std With BM ({avg_std_with_bm:.4f})')\n",
    "plt.axhline(y=avg_std_without_bm, color='red', linestyle='--', label=f'Avg. Std Without BM ({avg_std_without_bm:.4f})')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Standard Deviation of Time')\n",
    "plt.title('Standard Deviation Comparison Over Years')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Scatter Plot to compare the performances with and without indexes with respect to maximum time.\n",
    "# Also include the average maximum time comparison lines\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(df_with_bm.index, df_with_bm['max'], color='blue', label='With BM')\n",
    "plt.scatter(df_without_bm.index, df_without_bm['max'], color='red', label='Without BM')\n",
    "\n",
    "# Calculate and plot the average of maximum times for with_bm and without_bm\n",
    "avg_max_with_bm = df_with_bm['max'].mean()\n",
    "avg_max_without_bm = df_without_bm['max'].mean()\n",
    "\n",
    "plt.axhline(y=avg_max_with_bm, color='blue', linestyle='--', label=f'Avg. Max Time With BM ({avg_max_with_bm:.4f})')\n",
    "plt.axhline(y=avg_max_without_bm, color='red', linestyle='--', label=f'Avg. Max Time Without BM ({avg_max_without_bm:.4f})')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Maximum Time')\n",
    "plt.title('Maximum Time Scatter Plot Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7b4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
