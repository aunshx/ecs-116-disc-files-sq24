{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa2c5e6",
   "metadata": {},
   "source": [
    "## <span style=color:blue>DISCUSSION 5 - BENCHMARKING and VISUALIZATION</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee4f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import csv\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text as sql_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad14751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an utilities file util.py in a folder benchmarking and import it\n",
    "sys.path.append('benchmarking/')\n",
    "import util_main as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2060cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# test that utils.py has been imported well\n",
    "util.hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d047ad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the env file \n",
    "\n",
    "dotenv_path = 'variables.env'\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbb12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the env variables\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "schema = os.getenv('DISC_4_SCHEMA')\n",
    "port = os.getenv('DISC_4_PORT')\n",
    "host = os.getenv('DISC_4_HOST')\n",
    "database = os.getenv('DISC_4_DB')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832a1e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created db engine.\n"
     ]
    }
   ],
   "source": [
    "# Create the db engine \n",
    "\n",
    "db_eng = create_engine(f\"postgresql+psycopg2://postgres:postgres@{host}:{port}/{database}\",\n",
    "                       connect_args={'options': '-csearch_path={}'.format(schema)},\n",
    "                       isolation_level = 'SERIALIZABLE')\n",
    "\n",
    "print(\"Successfully created db engine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498969b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2009', 56),\n",
      " ('2010', 449),\n",
      " ('2011', 1905),\n",
      " ('2012', 3872),\n",
      " ('2013', 7317),\n",
      " ('2014', 14203),\n",
      " ('2015', 28465),\n",
      " ('2016', 42825),\n",
      " ('2017', 39464),\n",
      " ('2018', 41836),\n",
      " ('2019', 41273),\n",
      " ('2020', 10239),\n",
      " ('2021', 18463),\n",
      " ('2022', 26739),\n",
      " ('2023', 22383),\n",
      " ('2024', 511)]\n"
     ]
    }
   ],
   "source": [
    "# Check to see the count of tables \n",
    "\n",
    "q = \"\"\"select left(to_char(date, 'YYYY-MM-DD'),4) as year, count(*)\n",
    "from reviews\n",
    "group by year\n",
    "order by year\"\"\"\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    result = conn.execute(sql_text(q))\n",
    "\n",
    "result_list = result.fetchall()\n",
    "\n",
    "pprint.pp(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c41bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT l.id, l.name\n",
      "FROM listings l, reviews r \n",
      "WHERE l.id = r.listing_id\n",
      "  AND r.date >= '2015-01-01'\n",
      "  AND r.date <= '2015-12-31'\n",
      "ORDER BY l.id;\n"
     ]
    }
   ],
   "source": [
    "# Create a function to build a query for reviews for each year\n",
    "\n",
    "date_start = '2015-01-01'\n",
    "date_end = '2015-12-31'\n",
    "\n",
    "q = util.build_query_listings_reviews(date_start, date_end)\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ce80972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'listings_join_review_2009': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2009-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2009-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2010': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2010-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2010-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2011': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2011-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2011-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2012': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2012-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2012-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2013': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2013-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2013-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2014': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2014-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2014-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2015': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2015-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2015-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2016': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2016-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2016-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2017': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2017-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2017-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2018': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2018-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2018-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2019': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2019-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2019-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2020': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2020-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2020-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2021': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2021-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2021-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2022': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2022-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2022-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2023': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2023-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2023-12-31'\\n\"\n",
      "                              'ORDER BY l.id;',\n",
      " 'listings_join_review_2024': 'SELECT DISTINCT l.id, l.name\\n'\n",
      "                              'FROM listings l, reviews r \\n'\n",
      "                              'WHERE l.id = r.listing_id\\n'\n",
      "                              \"  AND r.date >= '2024-01-01'\\n\"\n",
      "                              \"  AND r.date <= '2024-12-31'\\n\"\n",
      "                              'ORDER BY l.id;'}\n"
     ]
    }
   ],
   "source": [
    "# Create function to build queries from the year 2009 to 2024\n",
    "\n",
    "q_dict = {}\n",
    "\n",
    "for yr in range(2009,2025):\n",
    "    q_name = 'listings_join_review_' + str(yr)\n",
    "    date_start = str(yr) + '-01-01'\n",
    "    date_end = str(yr) + '-12-31'\n",
    "    q_dict[q_name] = util.build_query_listings_reviews(date_start, date_end)\n",
    "    \n",
    "pprint.pp(q_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2182606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.111929,\n",
      " 0.105735,\n",
      " 0.108335,\n",
      " 0.096723,\n",
      " 0.091923,\n",
      " 0.099697,\n",
      " 0.119122,\n",
      " 0.106385,\n",
      " 0.083823,\n",
      " 0.111343]\n",
      "mean 0.1035 min 0.0838 max 0.1191 std 0.01\n"
     ]
    }
   ],
   "source": [
    "# Create a function to calculate the performance of a single query from q_dict\n",
    "\n",
    "count = 10\n",
    "\n",
    "time_list = []\n",
    "for i in range(0,count):\n",
    "    time_start = datetime.now()\n",
    "    # Open new db connection for each execution of the query to avoid multithreading\n",
    "    with db_eng.connect() as conn:\n",
    "        df = pd.read_sql(q_dict['listings_join_review_2015'], con=conn)\n",
    "\n",
    "    time_end = datetime.now()\n",
    "    diff = util.time_diff(time_start, time_end)\n",
    "    time_list.append(diff)\n",
    "\n",
    "pprint.pp(time_list)\n",
    "print('mean', round(sum(time_list)/len(time_list), 4), 'min', \\\n",
    "        round(min(time_list), 4), 'max', \\\n",
    "        round(max(time_list), 4), 'std', \\\n",
    "        round(np.std(time_list), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc330789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set of indexes on reviews is: \n",
      "[('new_york_city', 'reviews', 'date_in_reviews', None, 'CREATE INDEX date_in_reviews ON new_york_city.reviews USING btree (date)')]\n"
     ]
    }
   ],
   "source": [
    "# Adding and dropping indexes in the table reviews \n",
    "\n",
    "q_create_date_in_reviews = '''\n",
    "BEGIN TRANSACTION;\n",
    "CREATE INDEX IF NOT EXISTS date_in_reviews\n",
    "ON reviews(date);\n",
    "END TRANSACTION;\n",
    "'''\n",
    "\n",
    "q_drop_date_in_reviews = '''\n",
    "BEGIN TRANSACTION;\n",
    "DROP INDEX IF EXISTS date_in_reviews;\n",
    "END TRANSACTION;\n",
    "'''\n",
    "\n",
    "q_show_indexes_for_reviews = '''\n",
    "select *\n",
    "from pg_indexes\n",
    "where tablename = 'reviews';\n",
    "'''\n",
    "\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    conn.execute(sql_text(q_create_date_in_reviews))\n",
    "    result_reviews_add = conn.execute(sql_text(q_show_indexes_for_reviews))\n",
    "    print('The set of indexes on reviews is: ')\n",
    "    print(result_reviews_add.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a5ef050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_bm': {'2009': {'avg': 0.0111, 'min': 0.0, 'max': 0.024, 'std': 0.0076}, '2010': {'avg': 0.0126, 'min': 0.0, 'max': 0.026, 'std': 0.0081}, '2011': {'avg': 0.0246, 'min': 0.0147, 'max': 0.0508, 'std': 0.0105}, '2012': {'avg': 0.0178, 'min': 0.0153, 'max': 0.0231, 'std': 0.0021}, '2013': {'avg': 0.0354, 'min': 0.0157, 'max': 0.0674, 'std': 0.0149}, '2014': {'avg': 0.0489, 'min': 0.0301, 'max': 0.0815, 'std': 0.0165}, '2015': {'avg': 0.1093, 'min': 0.0648, 'max': 0.1529, 'std': 0.0242}, '2016': {'avg': 0.0874, 'min': 0.0482, 'max': 0.1904, 'std': 0.0298}, '2017': {'avg': 0.133, 'min': 0.094, 'max': 0.1778, 'std': 0.024}, '2018': {'avg': 0.0744, 'min': 0.0516, 'max': 0.0996, 'std': 0.012}, '2019': {'avg': 0.0511, 'min': 0.0313, 'max': 0.065, 'std': 0.0092}, '2020': {'avg': 0.0424, 'min': 0.0306, 'max': 0.0942, 'std': 0.0162}, '2021': {'avg': 0.0503, 'min': 0.0312, 'max': 0.0638, 'std': 0.0096}, '2022': {'avg': 0.0747, 'min': 0.0479, 'max': 0.1248, 'std': 0.0171}, '2023': {'avg': 0.0511, 'min': 0.0451, 'max': 0.0631, 'std': 0.0069}, '2024': {'avg': 0.0126, 'min': 0.0, 'max': 0.0236, 'std': 0.0063}}}\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics for each year\n",
    "\n",
    "#Initialize the count to 20\n",
    "count = 20\n",
    "\n",
    "perf_details = {}\n",
    "perf_details['with_bm'] = {}\n",
    "\n",
    "# Iterate through all the queries in q_dict\n",
    "for year, sql_query in q_dict.items():\n",
    "    time_list = []\n",
    "    for i in range(count): \n",
    "        time_start = datetime.now()\n",
    "\n",
    "        with db_eng.connect() as conn:\n",
    "            df = pd.read_sql(sql_query, con=conn)\n",
    "\n",
    "        time_end = datetime.now()\n",
    "        # Calulate the time difference\n",
    "        diff = util.time_diff(time_start, time_end)\n",
    "        time_list.append(diff)\n",
    "\n",
    "    # Splitting the string to get the year\n",
    "    parts = year.split('_')\n",
    "    curr_year = parts[-1]\n",
    "\n",
    "    # Calulcate the metrics\n",
    "    perf_profile = {\n",
    "        'avg': round(sum(time_list) / len(time_list), 4),\n",
    "        'min': round(min(time_list), 4),\n",
    "        'max': round(max(time_list), 4),\n",
    "        'std': round(np.std(time_list), 4)\n",
    "    }\n",
    "\n",
    "    # Add metrics according to the year\n",
    "    perf_details['with_bm'][curr_year] = perf_profile\n",
    "\n",
    "print(perf_details)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c536bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'with_bm': {   '2009': {   'avg': 0.0125,\n",
      "                               'max': 0.0312,\n",
      "                               'min': 0.0,\n",
      "                               'std': 0.0087},\n",
      "                   '2010': {   'avg': 0.0101,\n",
      "                               'max': 0.0236,\n",
      "                               'min': 0.0,\n",
      "                               'std': 0.0078},\n",
      "                   '2011': {   'avg': 0.0151,\n",
      "                               'max': 0.0309,\n",
      "                               'min': 0.0,\n",
      "                               'std': 0.006},\n",
      "                   '2012': {   'avg': 0.0179,\n",
      "                               'max': 0.0543,\n",
      "                               'min': 0.0062,\n",
      "                               'std': 0.0095},\n",
      "                   '2013': {   'avg': 0.0277,\n",
      "                               'max': 0.0324,\n",
      "                               'min': 0.0156,\n",
      "                               'std': 0.0061},\n",
      "                   '2014': {   'avg': 0.0448,\n",
      "                               'max': 0.0691,\n",
      "                               'min': 0.0312,\n",
      "                               'std': 0.012},\n",
      "                   '2015': {   'avg': 0.0804,\n",
      "                               'max': 0.1102,\n",
      "                               'min': 0.0625,\n",
      "                               'std': 0.0162},\n",
      "                   '2016': {   'avg': 0.0847,\n",
      "                               'max': 0.1261,\n",
      "                               'min': 0.0469,\n",
      "                               'std': 0.0226},\n",
      "                   '2017': {   'avg': 0.141,\n",
      "                               'max': 0.2038,\n",
      "                               'min': 0.0944,\n",
      "                               'std': 0.0252},\n",
      "                   '2018': {   'avg': 0.0616,\n",
      "                               'max': 0.0962,\n",
      "                               'min': 0.0469,\n",
      "                               'std': 0.0144},\n",
      "                   '2019': {   'avg': 0.059,\n",
      "                               'max': 0.1096,\n",
      "                               'min': 0.0318,\n",
      "                               'std': 0.0183},\n",
      "                   '2020': {   'avg': 0.0448,\n",
      "                               'max': 0.0633,\n",
      "                               'min': 0.0309,\n",
      "                               'std': 0.0111},\n",
      "                   '2021': {   'avg': 0.0556,\n",
      "                               'max': 0.1414,\n",
      "                               'min': 0.0312,\n",
      "                               'std': 0.0262},\n",
      "                   '2022': {   'avg': 0.0587,\n",
      "                               'max': 0.0813,\n",
      "                               'min': 0.0469,\n",
      "                               'std': 0.0119},\n",
      "                   '2023': {   'avg': 0.0582,\n",
      "                               'max': 0.0782,\n",
      "                               'min': 0.0463,\n",
      "                               'std': 0.0098},\n",
      "                   '2024': {   'avg': 0.0143,\n",
      "                               'max': 0.0241,\n",
      "                               'min': 0.0,\n",
      "                               'std': 0.0054}}}\n"
     ]
    }
   ],
   "source": [
    "# Create a seperate function for the above and put it in the util file.\n",
    "# Run it again to be sure  \n",
    "\n",
    "count = 20\n",
    "\n",
    "perf_details = {}\n",
    "\n",
    "perf_details['with_bm'] = util.calc_time_diff_per_year(db_eng, count, q_dict)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "pp.pprint(perf_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "720ce218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the index on date in reviews\n",
    "\n",
    "with db_eng.connect() as conn:\n",
    "    conn.execute(sql_text(q_drop_date_in_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the same metrics for review without the index\n",
    "\n",
    "perf_details['without_bm'] = util.calc_time_diff_per_year(db_eng, count, q_dict)\n",
    "\n",
    "pp.pprint(perf_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a way to save this data somewhere....save it in a json file (pref_data.json)\n",
    "\n",
    "perf_file = 'perf_data-main.json'\n",
    "\n",
    "try:\n",
    "    old_perf_summary = util.fetch_perf_data(perf_file)\n",
    "    print('Successfully read file perf_data/' + perf_file)\n",
    "except:\n",
    "    print('Not successful in finding file perf_data/' + perf_file + '; so creating it')\n",
    "    old_perf_summary = {}\n",
    "    util.write_perf_data(perf_details, perf_file)\n",
    "    \n",
    "util.write_perf_data(perf_details, perf_file)\n",
    "\n",
    "# With this we have completed the benchmarking test using a single index on the date column of the reviews table\n",
    "# However let's include visualization to see our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data from a file\n",
    "with open('perf_data/perf_data-main.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Printing the loaded file\n",
    "print(json.dumps(data, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the json into dataframes\n",
    "\n",
    "df_with_bm = pd.DataFrame(data['with_bm']).transpose()\n",
    "df_without_bm = pd.DataFrame(data['without_bm']).transpose()\n",
    "\n",
    "print(df_with_bm)\n",
    "print(df_without_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare the performances with and without indexes with respect to average time\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "index = range(len(df_with_bm))\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.bar(index, df_with_bm['avg'], bar_width, label='With BM')\n",
    "plt.bar([p + bar_width for p in index], df_without_bm['avg'], bar_width, label='Without BM')\n",
    "\n",
    "# Calculate and plot the average times for with_bm and without_bm\n",
    "avg_time_with_bm = df_with_bm['avg'].mean()\n",
    "avg_time_without_bm = df_without_bm['avg'].mean()\n",
    "\n",
    "plt.axhline(y=avg_time_with_bm, color='blue', linestyle='--', label=f'Avg. Time With BM ({avg_time_with_bm:.4f})')\n",
    "plt.axhline(y=avg_time_without_bm, color='red', linestyle='--', label=f'Avg. Time Without BM ({avg_time_without_bm:.4f})')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Time')\n",
    "plt.title('Average Performance Comparison With and Without Benchmarking')\n",
    "plt.xticks([p + bar_width / 2 for p in index], df_with_bm.index)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d02014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare the performances with and without indexes with respect to standard deviation\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot standard deviations\n",
    "plt.plot(df_with_bm.index, df_with_bm['std'], label='With BM', marker='o')\n",
    "plt.plot(df_without_bm.index, df_without_bm['std'], label='Without BM', marker='x')\n",
    "\n",
    "# Calculate and plot the average standard deviation for with_bm and without_bm\n",
    "avg_std_with_bm = df_with_bm['std'].mean()\n",
    "avg_std_without_bm = df_without_bm['std'].mean()\n",
    "\n",
    "plt.axhline(y=avg_std_with_bm, color='blue', linestyle='--', label=f'Avg. Std With BM ({avg_std_with_bm:.4f})')\n",
    "plt.axhline(y=avg_std_without_bm, color='red', linestyle='--', label=f'Avg. Std Without BM ({avg_std_without_bm:.4f})')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Standard Deviation of Time')\n",
    "plt.title('Standard Deviation Comparison Over Years')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d08915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare the performances with and without indexes with respect to maximum time\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(df_with_bm.index, df_with_bm['max'], color='blue', label='With BM')\n",
    "plt.scatter(df_without_bm.index, df_without_bm['max'], color='red', label='Without BM')\n",
    "\n",
    "# Calculate and plot the average of maximum times for with_bm and without_bm\n",
    "avg_max_with_bm = df_with_bm['max'].mean()\n",
    "avg_max_without_bm = df_without_bm['max'].mean()\n",
    "\n",
    "plt.axhline(y=avg_max_with_bm, color='blue', linestyle='--', label=f'Avg. Max Time With BM ({avg_max_with_bm:.4f})')\n",
    "plt.axhline(y=avg_max_without_bm, color='red', linestyle='--', label=f'Avg. Max Time Without BM ({avg_max_without_bm:.4f})')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Maximum Time')\n",
    "plt.title('Maximum Time Scatter Plot Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7b4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
